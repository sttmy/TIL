{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9234ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475e02d",
   "metadata": {},
   "source": [
    "## 8-5. RNN 언어모델 Recurrent Neural Network Language Model, RNNLM)\n",
    "\n",
    "(n-gram 언어 모델과 NNLM)\n",
    "- 고정된 개수의 단어만을 입력으로 받아야한다는 단점이 있었음\n",
    "\n",
    "(RNN)\n",
    "- 시점(time step)이라는 개념이 도입된 언어 모델\n",
    "- 입력의 길이를 고정하지 않을 수 있음\n",
    "- RNN으로 만든 언어 모델을 RNNLM(Recurrent Neural Network Language Model)이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4966f157",
   "metadata": {},
   "source": [
    "언어 모델은 주어진 단어 시퀀스로부터 다음 단어를 예측하는 모델\n",
    "\n",
    "코퍼스 예문: 'what will the fat cat sit on'\n",
    "\n",
    "↓ RNNLM은 기본적으로 예측 과정에서 이전 시점의 출력을 현재 시점의 입력으로 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f68dde",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('Data/230630/1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1eb9db",
   "metadata": {},
   "source": [
    "will, the, fat, cat, sit, on은 각 시점의 레이블임 \n",
    "\n",
    "what >>> will\n",
    "\n",
    "what will >>>> the\n",
    "\n",
    "what will the >>> fat\n",
    "\n",
    "what will the fat >>> cat\n",
    "\n",
    "what will the fat cat >>> sit\n",
    "\n",
    "what will the fat cat sit 입력 >>> will the fat cat sit on을 예측하도록 훈련됨\n",
    "\n",
    "#### :: 교사 강요(teacher forcing)\n",
    "- 테스트 과정에서 t 시점의 출력(→실제 알고 있는 정답)이 t+1 시점의 입력으로 사용되는 RNN 모델을 훈련시킬 때 사용하는 훈련 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1cf1710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('Data/230630/2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7da9af",
   "metadata": {},
   "source": [
    "훈련 과정 동안 출력층에서 사용하는 활성화 함수는 소프트맥스 함수\n",
    "\n",
    "모델이 예측한 값과 실제 레이블과의 오차를 계산하기 위해서 손실 함수로 크로스 엔트로피 함수를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cae756",
   "metadata": {},
   "source": [
    "#### RNNLM의 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99280c05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('Data/230630/3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9740cb70",
   "metadata": {},
   "source": [
    "- 총 4개의 층(layer)으로 이루어진 인공 신경망\n",
    "- 입력층(input layer)\n",
    "    - RNNLM의 현 시점(timestep)은 4로 가정\n",
    "    - 4번째 입력 단어인 fat의 원-핫 벡터가 입력됨\n",
    "\n",
    "- 임베딩층(embedding layer) = 투사층(projection layer)\n",
    "    - 단어 집합의 크기가 V일 때, 임베딩 벡터의 크기를 M으로 설정하면, \n",
    "    <br> 각 입력 단어들은 임베딩층에서 V × M 크기의 임베딩 행렬과 곱해짐\n",
    "    <br> V는 단어 집합의 크기\n",
    "    - 만약 원-핫 벡터의 차원이 7이고, M이 5라면 임베딩 행렬은 7 × 5 행렬이 됨\n",
    "    <br> 이 임베딩 행렬은 역전파 과정에서 다른 가중치들과 함께 학습됨\n",
    "    <br>$$e_t = lookup(x_t)$$\n",
    "- 은닉층\n",
    "$$ h_t = tanh(W_xe_t + W_hh_{t-1} + b) $$\n",
    "\n",
    "- 출력층(output layer)\n",
    "    - 모델이 예측해야하는 정답에 해당되는 단어 cat의 원-핫 벡터는 출력층에서 모델이 예측한 값의 오차를 구하기 위해 사용될 예정\n",
    "    - 이 오차로부터 손실 함수를 사용해 인공 신경망이 학습\n",
    "    - softmax함수를 거치며 (0~1) 사이 실수값을 갖게 됨\n",
    "$$ \\hat{y_t} = softmax(W_yh_t + b)$$\n",
    "    - $ \\hat{y_t} $의 $j$번째 인덱스가 가진 값은, $j$번째 단어가 다음 단어일 확률을 나타냄\n",
    "    - $ \\hat{y_t} $은 실제값에 해당되는 원핫벡터의 값에 가까워져야 함\n",
    "    - 이를 위해 손실함수로 cross-entropy함수를 사용\n",
    "    \n",
    "- 결국 가중치 행렬은 $E, W_x, W_h, W_y$ 4개임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31777398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('Data/230630/4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6edc8b",
   "metadata": {},
   "source": [
    "## 8-6. RNN을 이용한 텍스트 생성 Text Generation using RNN\n",
    "\n",
    "- many-to-one 구조의 RNN 사용, 문맥을 반영해 텍스트를 생성하는 모델 만들기\n",
    "- 예) '경마장에 있는 말이 뛰고 있다'\n",
    "<br> '그의 말이 법이다'\n",
    "<br> '가는 말이 고와야 오는 말이 곱다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80cf2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "text = \"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
    "그의 말이 법이다\\n\n",
    "가는 말이 고와야 오는 말이 곱다\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b15fca31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 12\n"
     ]
    }
   ],
   "source": [
    "# 단어집합 생성하고 크기 확인하기\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "# 단어집합 저장할 때는 Keras 토크나이저 정수 인코딩이 1부터 시작, 패딩을 위한 0을 고려하여 +1\n",
    "print('단어 집합의 크기 : %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "685b98f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'말이': 1,\n",
       " '경마장에': 2,\n",
       " '있는': 3,\n",
       " '뛰고': 4,\n",
       " '있다': 5,\n",
       " '그의': 6,\n",
       " '법이다': 7,\n",
       " '가는': 8,\n",
       " '고와야': 9,\n",
       " '오는': 10,\n",
       " '곱다': 11}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3327b5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['경마장에 있는 말이 뛰고 있다', '', '그의 말이 법이다', '', '가는 말이 고와야 오는 말이 곱다', '']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa822982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 1, 4, 5]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([text.split('\\n')[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d29f7cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 1, 7]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([text.split('\\n')[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c13ad68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8, 1, 9, 10, 1, 11]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([text.split('\\n')[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28f10624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습에 사용할 샘플의 개수: 11\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "for line in text.split('\\n'): # 줄바꿈 문자를 기준으로 문장 토큰화\n",
    "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "print('학습에 사용할 샘플의 개수: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a305a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3],\n",
       " [2, 3, 1],\n",
       " [2, 3, 1, 4],\n",
       " [2, 3, 1, 4, 5],\n",
       " [6, 1],\n",
       " [6, 1, 7],\n",
       " [8, 1],\n",
       " [8, 1, 9],\n",
       " [8, 1, 9, 10],\n",
       " [8, 1, 9, 10, 1],\n",
       " [8, 1, 9, 10, 1, 11]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074eeb6b",
   "metadata": {},
   "source": [
    "↑ 위의 데이터는 아직 레이블로 사용될 단어를 분리하지 않은 훈련 데이터\n",
    "\n",
    "[2, 3]은 [경마장에, 있는]에 해당되며 [2, 3, 1]은 [경마장에, 있는, 말이]에 해당\n",
    "\n",
    "전체 훈련 데이터에 대해서 맨 우측에 있는 단어에 대해서만 레이블로 분리해야 함\n",
    "\n",
    "우선 전체 샘플에 대해서 길이를 일치시켜 줍니다. 가장 긴 샘플의 길이를 기준으로 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3cded9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 6\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in sequences) # 모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\n",
    "print('샘플의 최대 길이 : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b647f",
   "metadata": {},
   "source": [
    "pad_sequences()는 모든 샘플에 대해서 0을 사용하여 길이를 맞춰줌 (maxlen을 최대 길이로 패딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3218dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 샘플의 길이를 max_len = 6으로 패딩\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4c61989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  2,  3],\n",
       "       [ 0,  0,  0,  2,  3,  1],\n",
       "       [ 0,  0,  2,  3,  1,  4],\n",
       "       [ 0,  2,  3,  1,  4,  5],\n",
       "       [ 0,  0,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  6,  1,  7],\n",
       "       [ 0,  0,  0,  0,  8,  1],\n",
       "       [ 0,  0,  0,  8,  1,  9],\n",
       "       [ 0,  0,  8,  1,  9, 10],\n",
       "       [ 0,  8,  1,  9, 10,  1],\n",
       "       [ 8,  1,  9, 10,  1, 11]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c43f4e",
   "metadata": {},
   "source": [
    "이제 각 샘플의 마지막 단어를 레이블로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ace62e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "x = sequences[:,:-1]\n",
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37afe584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  2,  3],\n",
       "       [ 0,  0,  2,  3,  1],\n",
       "       [ 0,  2,  3,  1,  4],\n",
       "       [ 0,  0,  0,  0,  6],\n",
       "       [ 0,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  0,  8],\n",
       "       [ 0,  0,  0,  8,  1],\n",
       "       [ 0,  0,  8,  1,  9],\n",
       "       [ 0,  8,  1,  9, 10],\n",
       "       [ 8,  1,  9, 10,  1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e96a91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  1,  4,  5,  1,  7,  1,  9, 10,  1, 11])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d500d7",
   "metadata": {},
   "source": [
    "RNN 모델에 훈련 데이터를 훈련 시키기 전에 레이블에 대해서 원-핫 인코딩을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5bf96ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "642255a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2134d4f",
   "metadata": {},
   "source": [
    "#### 모델 설계하기: RNN모델에 데이터 훈련시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af034c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 2.4600 - accuracy: 0.2727 - 901ms/epoch - 901ms/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 2.4448 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 2.4293 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 2.4136 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 2.3975 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.3810 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.3638 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.3459 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.3273 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 2.3077 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 2.2872 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 2.2656 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 2.2430 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 2.2194 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 15/200\n",
      "1/1 - 0s - loss: 2.1948 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 16/200\n",
      "1/1 - 0s - loss: 2.1693 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 17/200\n",
      "1/1 - 0s - loss: 2.1431 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 18/200\n",
      "1/1 - 0s - loss: 2.1162 - accuracy: 0.3636 - 2ms/epoch - 2ms/step\n",
      "Epoch 19/200\n",
      "1/1 - 0s - loss: 2.0891 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 20/200\n",
      "1/1 - 0s - loss: 2.0619 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 21/200\n",
      "1/1 - 0s - loss: 2.0351 - accuracy: 0.3636 - 17ms/epoch - 17ms/step\n",
      "Epoch 22/200\n",
      "1/1 - 0s - loss: 2.0091 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 23/200\n",
      "1/1 - 0s - loss: 1.9843 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 24/200\n",
      "1/1 - 0s - loss: 1.9613 - accuracy: 0.3636 - 17ms/epoch - 17ms/step\n",
      "Epoch 25/200\n",
      "1/1 - 0s - loss: 1.9403 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
      "Epoch 26/200\n",
      "1/1 - 0s - loss: 1.9215 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 27/200\n",
      "1/1 - 0s - loss: 1.9048 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 28/200\n",
      "1/1 - 0s - loss: 1.8898 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 29/200\n",
      "1/1 - 0s - loss: 1.8759 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 30/200\n",
      "1/1 - 0s - loss: 1.8625 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 31/200\n",
      "1/1 - 0s - loss: 1.8488 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 32/200\n",
      "1/1 - 0s - loss: 1.8344 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 33/200\n",
      "1/1 - 0s - loss: 1.8191 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 34/200\n",
      "1/1 - 0s - loss: 1.8029 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 35/200\n",
      "1/1 - 0s - loss: 1.7861 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 36/200\n",
      "1/1 - 0s - loss: 1.7691 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 37/200\n",
      "1/1 - 0s - loss: 1.7521 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 38/200\n",
      "1/1 - 0s - loss: 1.7353 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 39/200\n",
      "1/1 - 0s - loss: 1.7190 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 40/200\n",
      "1/1 - 0s - loss: 1.7031 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 41/200\n",
      "1/1 - 0s - loss: 1.6873 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 42/200\n",
      "1/1 - 0s - loss: 1.6714 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 43/200\n",
      "1/1 - 0s - loss: 1.6552 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 44/200\n",
      "1/1 - 0s - loss: 1.6385 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 45/200\n",
      "1/1 - 0s - loss: 1.6213 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 46/200\n",
      "1/1 - 0s - loss: 1.6034 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 47/200\n",
      "1/1 - 0s - loss: 1.5850 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 48/200\n",
      "1/1 - 0s - loss: 1.5662 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 49/200\n",
      "1/1 - 0s - loss: 1.5472 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 50/200\n",
      "1/1 - 0s - loss: 1.5280 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 51/200\n",
      "1/1 - 0s - loss: 1.5087 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 52/200\n",
      "1/1 - 0s - loss: 1.4894 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 53/200\n",
      "1/1 - 0s - loss: 1.4702 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 54/200\n",
      "1/1 - 0s - loss: 1.4508 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 55/200\n",
      "1/1 - 0s - loss: 1.4314 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 56/200\n",
      "1/1 - 0s - loss: 1.4118 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 57/200\n",
      "1/1 - 0s - loss: 1.3922 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 58/200\n",
      "1/1 - 0s - loss: 1.3725 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 59/200\n",
      "1/1 - 0s - loss: 1.3529 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 60/200\n",
      "1/1 - 0s - loss: 1.3334 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 61/200\n",
      "1/1 - 0s - loss: 1.3141 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 62/200\n",
      "1/1 - 0s - loss: 1.2951 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 63/200\n",
      "1/1 - 0s - loss: 1.2764 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 64/200\n",
      "1/1 - 0s - loss: 1.2581 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 65/200\n",
      "1/1 - 0s - loss: 1.2400 - accuracy: 0.6364 - 3ms/epoch - 3ms/step\n",
      "Epoch 66/200\n",
      "1/1 - 0s - loss: 1.2222 - accuracy: 0.6364 - 3ms/epoch - 3ms/step\n",
      "Epoch 67/200\n",
      "1/1 - 0s - loss: 1.2046 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
      "Epoch 68/200\n",
      "1/1 - 0s - loss: 1.1873 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 69/200\n",
      "1/1 - 0s - loss: 1.1701 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 70/200\n",
      "1/1 - 0s - loss: 1.1532 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
      "Epoch 71/200\n",
      "1/1 - 0s - loss: 1.1365 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 72/200\n",
      "1/1 - 0s - loss: 1.1201 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 73/200\n",
      "1/1 - 0s - loss: 1.1040 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 74/200\n",
      "1/1 - 0s - loss: 1.0881 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 75/200\n",
      "1/1 - 0s - loss: 1.0726 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 76/200\n",
      "1/1 - 0s - loss: 1.0573 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 77/200\n",
      "1/1 - 0s - loss: 1.0422 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 78/200\n",
      "1/1 - 0s - loss: 1.0275 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 79/200\n",
      "1/1 - 0s - loss: 1.0129 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 80/200\n",
      "1/1 - 0s - loss: 0.9986 - accuracy: 0.8182 - 4ms/epoch - 4ms/step\n",
      "Epoch 81/200\n",
      "1/1 - 0s - loss: 0.9846 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 82/200\n",
      "1/1 - 0s - loss: 0.9708 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 83/200\n",
      "1/1 - 0s - loss: 0.9572 - accuracy: 0.8182 - 16ms/epoch - 16ms/step\n",
      "Epoch 84/200\n",
      "1/1 - 0s - loss: 0.9439 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 85/200\n",
      "1/1 - 0s - loss: 0.9308 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 86/200\n",
      "1/1 - 0s - loss: 0.9179 - accuracy: 0.8182 - 16ms/epoch - 16ms/step\n",
      "Epoch 87/200\n",
      "1/1 - 0s - loss: 0.9052 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 88/200\n",
      "1/1 - 0s - loss: 0.8927 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 89/200\n",
      "1/1 - 0s - loss: 0.8803 - accuracy: 0.8182 - 17ms/epoch - 17ms/step\n",
      "Epoch 90/200\n",
      "1/1 - 0s - loss: 0.8681 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 91/200\n",
      "1/1 - 0s - loss: 0.8561 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 92/200\n",
      "1/1 - 0s - loss: 0.8442 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 93/200\n",
      "1/1 - 0s - loss: 0.8325 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 94/200\n",
      "1/1 - 0s - loss: 0.8209 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 95/200\n",
      "1/1 - 0s - loss: 0.8095 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 96/200\n",
      "1/1 - 0s - loss: 0.7983 - accuracy: 0.8182 - 17ms/epoch - 17ms/step\n",
      "Epoch 97/200\n",
      "1/1 - 0s - loss: 0.7871 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 98/200\n",
      "1/1 - 0s - loss: 0.7761 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 99/200\n",
      "1/1 - 0s - loss: 0.7652 - accuracy: 0.8182 - 17ms/epoch - 17ms/step\n",
      "Epoch 100/200\n",
      "1/1 - 0s - loss: 0.7545 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 101/200\n",
      "1/1 - 0s - loss: 0.7439 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 102/200\n",
      "1/1 - 0s - loss: 0.7335 - accuracy: 0.8182 - 15ms/epoch - 15ms/step\n",
      "Epoch 103/200\n",
      "1/1 - 0s - loss: 0.7231 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 104/200\n",
      "1/1 - 0s - loss: 0.7129 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 105/200\n",
      "1/1 - 0s - loss: 0.7028 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 106/200\n",
      "1/1 - 0s - loss: 0.6929 - accuracy: 0.8182 - 4ms/epoch - 4ms/step\n",
      "Epoch 107/200\n",
      "1/1 - 0s - loss: 0.6830 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 108/200\n",
      "1/1 - 0s - loss: 0.6733 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 109/200\n",
      "1/1 - 0s - loss: 0.6637 - accuracy: 0.8182 - 1ms/epoch - 1ms/step\n",
      "Epoch 110/200\n",
      "1/1 - 0s - loss: 0.6543 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 111/200\n",
      "1/1 - 0s - loss: 0.6449 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 112/200\n",
      "1/1 - 0s - loss: 0.6357 - accuracy: 0.8182 - 16ms/epoch - 16ms/step\n",
      "Epoch 113/200\n",
      "1/1 - 0s - loss: 0.6265 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 114/200\n",
      "1/1 - 0s - loss: 0.6175 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 115/200\n",
      "1/1 - 0s - loss: 0.6086 - accuracy: 0.8182 - 18ms/epoch - 18ms/step\n",
      "Epoch 116/200\n",
      "1/1 - 0s - loss: 0.5998 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 117/200\n",
      "1/1 - 0s - loss: 0.5911 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 118/200\n",
      "1/1 - 0s - loss: 0.5824 - accuracy: 0.8182 - 15ms/epoch - 15ms/step\n",
      "Epoch 119/200\n",
      "1/1 - 0s - loss: 0.5739 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 120/200\n",
      "1/1 - 0s - loss: 0.5655 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 121/200\n",
      "1/1 - 0s - loss: 0.5572 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 122/200\n",
      "1/1 - 0s - loss: 0.5490 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 123/200\n",
      "1/1 - 0s - loss: 0.5409 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 124/200\n",
      "1/1 - 0s - loss: 0.5329 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 125/200\n",
      "1/1 - 0s - loss: 0.5250 - accuracy: 0.9091 - 16ms/epoch - 16ms/step\n",
      "Epoch 126/200\n",
      "1/1 - 0s - loss: 0.5172 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 127/200\n",
      "1/1 - 0s - loss: 0.5095 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 128/200\n",
      "1/1 - 0s - loss: 0.5019 - accuracy: 0.9091 - 15ms/epoch - 15ms/step\n",
      "Epoch 129/200\n",
      "1/1 - 0s - loss: 0.4944 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 130/200\n",
      "1/1 - 0s - loss: 0.4870 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 131/200\n",
      "1/1 - 0s - loss: 0.4796 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 132/200\n",
      "1/1 - 0s - loss: 0.4724 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 133/200\n",
      "1/1 - 0s - loss: 0.4653 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 134/200\n",
      "1/1 - 0s - loss: 0.4582 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 135/200\n",
      "1/1 - 0s - loss: 0.4512 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 136/200\n",
      "1/1 - 0s - loss: 0.4444 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 137/200\n",
      "1/1 - 0s - loss: 0.4376 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 138/200\n",
      "1/1 - 0s - loss: 0.4309 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 139/200\n",
      "1/1 - 0s - loss: 0.4243 - accuracy: 0.9091 - 934us/epoch - 934us/step\n",
      "Epoch 140/200\n",
      "1/1 - 0s - loss: 0.4177 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 141/200\n",
      "1/1 - 0s - loss: 0.4113 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 142/200\n",
      "1/1 - 0s - loss: 0.4049 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 143/200\n",
      "1/1 - 0s - loss: 0.3987 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 144/200\n",
      "1/1 - 0s - loss: 0.3925 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 145/200\n",
      "1/1 - 0s - loss: 0.3863 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 146/200\n",
      "1/1 - 0s - loss: 0.3803 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 147/200\n",
      "1/1 - 0s - loss: 0.3743 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 148/200\n",
      "1/1 - 0s - loss: 0.3685 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 149/200\n",
      "1/1 - 0s - loss: 0.3626 - accuracy: 0.9091 - 16ms/epoch - 16ms/step\n",
      "Epoch 150/200\n",
      "1/1 - 0s - loss: 0.3569 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 151/200\n",
      "1/1 - 0s - loss: 0.3512 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 152/200\n",
      "1/1 - 0s - loss: 0.3456 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 153/200\n",
      "1/1 - 0s - loss: 0.3401 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 154/200\n",
      "1/1 - 0s - loss: 0.3347 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 155/200\n",
      "1/1 - 0s - loss: 0.3293 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 156/200\n",
      "1/1 - 0s - loss: 0.3239 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 157/200\n",
      "1/1 - 0s - loss: 0.3187 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 158/200\n",
      "1/1 - 0s - loss: 0.3135 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 159/200\n",
      "1/1 - 0s - loss: 0.3084 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 160/200\n",
      "1/1 - 0s - loss: 0.3033 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 161/200\n",
      "1/1 - 0s - loss: 0.2983 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 162/200\n",
      "1/1 - 0s - loss: 0.2934 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 163/200\n",
      "1/1 - 0s - loss: 0.2885 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 164/200\n",
      "1/1 - 0s - loss: 0.2837 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 165/200\n",
      "1/1 - 0s - loss: 0.2789 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 166/200\n",
      "1/1 - 0s - loss: 0.2743 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 167/200\n",
      "1/1 - 0s - loss: 0.2696 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 168/200\n",
      "1/1 - 0s - loss: 0.2651 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 169/200\n",
      "1/1 - 0s - loss: 0.2605 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 170/200\n",
      "1/1 - 0s - loss: 0.2561 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 171/200\n",
      "1/1 - 0s - loss: 0.2517 - accuracy: 0.9091 - 544us/epoch - 544us/step\n",
      "Epoch 172/200\n",
      "1/1 - 0s - loss: 0.2474 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 173/200\n",
      "1/1 - 0s - loss: 0.2431 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 174/200\n",
      "1/1 - 0s - loss: 0.2389 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 175/200\n",
      "1/1 - 0s - loss: 0.2348 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 176/200\n",
      "1/1 - 0s - loss: 0.2307 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 177/200\n",
      "1/1 - 0s - loss: 0.2266 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 178/200\n",
      "1/1 - 0s - loss: 0.2227 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "Epoch 179/200\n",
      "1/1 - 0s - loss: 0.2187 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 180/200\n",
      "1/1 - 0s - loss: 0.2149 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 181/200\n",
      "1/1 - 0s - loss: 0.2111 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "Epoch 182/200\n",
      "1/1 - 0s - loss: 0.2074 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 183/200\n",
      "1/1 - 0s - loss: 0.2037 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 184/200\n",
      "1/1 - 0s - loss: 0.2001 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 185/200\n",
      "1/1 - 0s - loss: 0.1965 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "Epoch 186/200\n",
      "1/1 - 0s - loss: 0.1930 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 187/200\n",
      "1/1 - 0s - loss: 0.1895 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 188/200\n",
      "1/1 - 0s - loss: 0.1861 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "Epoch 189/200\n",
      "1/1 - 0s - loss: 0.1828 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 190/200\n",
      "1/1 - 0s - loss: 0.1795 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 191/200\n",
      "1/1 - 0s - loss: 0.1763 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 192/200\n",
      "1/1 - 0s - loss: 0.1731 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "Epoch 193/200\n",
      "1/1 - 0s - loss: 0.1700 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 194/200\n",
      "1/1 - 0s - loss: 0.1670 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 195/200\n",
      "1/1 - 0s - loss: 0.1640 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "Epoch 196/200\n",
      "1/1 - 0s - loss: 0.1610 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 197/200\n",
      "1/1 - 0s - loss: 0.1581 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 198/200\n",
      "1/1 - 0s - loss: 0.1553 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 199/200\n",
      "1/1 - 0s - loss: 0.1525 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
      "Epoch 200/200\n",
      "1/1 - 0s - loss: 0.1498 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2183f695f70>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN\n",
    "\n",
    "embedding_dim = 10\n",
    "hidden_units = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(SimpleRNN(hidden_units))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0509bace",
   "metadata": {},
   "source": [
    "임베딩 벡터의 차원은 10, 은닉 상태의 크기는 32\n",
    "\n",
    "다 대 일 구조의 RNN을 사용\n",
    "\n",
    "전결합층(Fully Connected Layer)을 출력층으로 단어 집합 크기만큼의 뉴런을 배치하여 모델을 설계\n",
    "\n",
    "마지막 시점에서 모든 가능한 단어 중 하나의 단어를 예측하는 다중 클래스 분류 문제를 수행하는 모델임 (손실함수: crossentropy, 출력층 활성화함수: softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bec630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이 정확하게 예측하고 있는지 문장을 생성하는 함수를 만들어서 출력\n",
    "\n",
    "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    init_word = current_word\n",
    "    sentence = ''\n",
    "\n",
    "    # n번 반복\n",
    "    for _ in range(n):\n",
    "        # 현재 단어에 대한 정수 인코딩과 패딩\n",
    "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
    "        # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        result = np.argmax(result, axis=1)\n",
    "\n",
    "        for word, index in tokenizer.word_index.items(): \n",
    "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면 break\n",
    "            if index == result:\n",
    "                break\n",
    "\n",
    "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "        current_word = current_word + ' '  + word\n",
    "\n",
    "        # 예측 단어를 문장에 저장\n",
    "        sentence = sentence + ' ' + word\n",
    "\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "817c14ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경마장에 있는 말이 뛰고 있다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '경마장에', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0cd37af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그의 말이 법이다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '그의', 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b533582c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가는 말이 고와야 오는 말이 곱다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '가는', 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d1519c",
   "metadata": {},
   "source": [
    "앞의 문맥을 기준으로 '말이' 라는 단어 다음에 나올 단어를 기존의 훈련 데이터와 일치하게 예측함\n",
    "\n",
    "이 모델은 충분한 훈련 데이터를 갖고 있지 못하므로 위에서 문장의 길이에 맞게 적절하게 예측해야하는 횟수 4, 2, 5를 각각 인자값으로 주었음\n",
    "\n",
    "이 이상의 숫자를 주면 기계는 '있다', '법이다', '곱다' 다음에 나오는 단어가 무엇인지 배운 적이 없으므로 임의 예측을 함\n",
    "\n",
    "#### 아래부터는 더 많은 훈련 데이터를 가지고 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3970f3",
   "metadata": {},
   "source": [
    "### LSTM 이용해 텍스트 생성\n",
    "\n",
    "뉴욕 타임즈 기사의 제목데이터\n",
    "\n",
    "https://www.kaggle.com/aashita/nyt-comments ArticlesApril2018.csv 데이터를 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fbae164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1754cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781</td>\n",
       "      <td>By JOHN BRANCH</td>\n",
       "      <td>article</td>\n",
       "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
       "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
       "      <td>68</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:16:49</td>\n",
       "      <td>Pro Football</td>\n",
       "      <td>“I understand that they could meet with us, pa...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5adf653f068401528a2aa697</td>\n",
       "      <td>656</td>\n",
       "      <td>By LISA FRIEDMAN</td>\n",
       "      <td>article</td>\n",
       "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
       "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
       "      <td>68</td>\n",
       "      <td>Climate</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:11:21</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The agency plans to publish a new regulation T...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5adf4626068401528a2aa628</td>\n",
       "      <td>2427</td>\n",
       "      <td>By PETE WELLS</td>\n",
       "      <td>article</td>\n",
       "      <td>The New Noma, Explained</td>\n",
       "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
       "      <td>66</td>\n",
       "      <td>Dining</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:58:44</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>What’s it like to eat at the second incarnatio...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5adf40d2068401528a2aa619</td>\n",
       "      <td>626</td>\n",
       "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
       "      <td>68</td>\n",
       "      <td>Washington</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:35:57</td>\n",
       "      <td>Europe</td>\n",
       "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5adf3d64068401528a2aa60f</td>\n",
       "      <td>815</td>\n",
       "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
       "      <td>68</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:21:21</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  articleID  articleWordCount   \n",
       "0  5adf6684068401528a2aa69b               781  \\\n",
       "1  5adf653f068401528a2aa697               656   \n",
       "2  5adf4626068401528a2aa628              2427   \n",
       "3  5adf40d2068401528a2aa619               626   \n",
       "4  5adf3d64068401528a2aa60f               815   \n",
       "\n",
       "                                      byline documentType   \n",
       "0                             By JOHN BRANCH      article  \\\n",
       "1                           By LISA FRIEDMAN      article   \n",
       "2                              By PETE WELLS      article   \n",
       "3  By JULIE HIRSCHFELD DAVIS and PETER BAKER      article   \n",
       "4             By IAN AUSTEN and DAN BILEFSKY      article   \n",
       "\n",
       "                                            headline   \n",
       "0  Former N.F.L. Cheerleaders’ Settlement Offer: ...  \\\n",
       "1  E.P.A. to Unveil a New Rule. Its Effect: Less ...   \n",
       "2                            The New Noma, Explained   \n",
       "3                                            Unknown   \n",
       "4                                            Unknown   \n",
       "\n",
       "                                            keywords  multimedia     newDesk   \n",
       "0  ['Workplace Hazards and Violations', 'Football...          68      Sports  \\\n",
       "1  ['Environmental Protection Agency', 'Pruitt, S...          68     Climate   \n",
       "2  ['Restaurants', 'Noma (Copenhagen, Restaurant)...          66      Dining   \n",
       "3  ['Macron, Emmanuel (1977- )', 'Trump, Donald J...          68  Washington   \n",
       "4  ['Toronto, Ontario, Attack (April, 2018)', 'Mu...          68     Foreign   \n",
       "\n",
       "   printPage              pubDate   sectionName   \n",
       "0          0  2018-04-24 17:16:49  Pro Football  \\\n",
       "1          0  2018-04-24 17:11:21       Unknown   \n",
       "2          0  2018-04-24 14:58:44       Unknown   \n",
       "3          0  2018-04-24 14:35:57        Europe   \n",
       "4          0  2018-04-24 14:21:21        Canada   \n",
       "\n",
       "                                             snippet              source   \n",
       "0  “I understand that they could meet with us, pa...  The New York Times  \\\n",
       "1  The agency plans to publish a new regulation T...  The New York Times   \n",
       "2  What’s it like to eat at the second incarnatio...  The New York Times   \n",
       "3  President Trump welcomed President Emmanuel Ma...  The New York Times   \n",
       "4  Alek Minassian, 25, a resident of Toronto’s Ri...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           News  https://www.nytimes.com/2018/04/24/sports/foot...  \n",
       "1           News  https://www.nytimes.com/2018/04/24/climate/epa...  \n",
       "2           News  https://www.nytimes.com/2018/04/24/dining/noma...  \n",
       "3           News  https://www.nytimes.com/2018/04/24/world/europ...  \n",
       "4           News  https://www.nytimes.com/2018/04/24/world/canad...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/230630/ArticlesApril2018.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "294ac066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "열의 개수:  15\n",
      "Index(['articleID', 'articleWordCount', 'byline', 'documentType', 'headline',\n",
      "       'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n",
      "       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('열의 개수: ',len(df.columns))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbc8fcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# headline 열 Null 값이 있는지 확인\n",
    "df['headline'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eae17564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'Unknown',\n",
       " 'Unknown']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# headline 열에서 모든 신문 기사의 제목을 뽑아서 하나의 리스트로 저장\n",
    "headline = []\n",
    "# 헤드라인의 값들을 리스트로 저장\n",
    "headline.extend(list(df.headline.values)) \n",
    "headline[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb4cee9",
   "metadata": {},
   "source": [
    "#### Unknwon이 있으므로, 노이즈 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5962495f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 개수 : 1324\n",
      "노이즈값 제거 후 샘플의 개수 : 1214\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플의 개수 : {}'.format(len(headline)))\n",
    "headline = [word for word in headline if word != \"Unknown\"]\n",
    "print('노이즈값 제거 후 샘플의 개수 : {}'.format(len(headline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6066464d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
       " 'Is School a Place for Self-Expression?']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10751f2",
   "metadata": {},
   "source": [
    "#### 구두점 제거와 단어 소문자화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4dc4a753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
       " 'epa to unveil a new rule its effect less science in policymaking',\n",
       " 'the new noma explained',\n",
       " 'how a bag of texas dirt  became a times tradition',\n",
       " 'is school a place for selfexpression']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def repreprocessing(raw_sentence):\n",
    "    preprocessed_sentence = raw_sentence.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    # 구두점 제거와 동시에 소문자화\n",
    "    return ''.join(word for word in preprocessed_sentence if word not in punctuation).lower()\n",
    "\n",
    "preprocessed_headline = [repreprocessing(x) for x in headline]\n",
    "preprocessed_headline[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e789385c",
   "metadata": {},
   "source": [
    "#### 단어 집합(vocabulary)을 만들고 크기를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "993862bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 3494\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(preprocessed_headline)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('단어 집합의 크기 : %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9957bf22",
   "metadata": {},
   "source": [
    "#### 훈련데이터 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d69f9458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99, 269],\n",
       " [99, 269, 371],\n",
       " [99, 269, 371, 1115],\n",
       " [99, 269, 371, 1115, 582],\n",
       " [99, 269, 371, 1115, 582, 52],\n",
       " [99, 269, 371, 1115, 582, 52, 7],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
       " [100, 3]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = list()\n",
    "\n",
    "for sentence in preprocessed_headline:\n",
    "\n",
    "    # 각 샘플에 대한 정수 인코딩\n",
    "    encoded = tokenizer.texts_to_sequences([sentence])[0] \n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "sequences[:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e047b70",
   "metadata": {},
   "source": [
    "#### index_to_word 어떤 정수가 어떤 단어를 의미하는지 알아봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c21efc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 상위 582번 단어 : offer\n"
     ]
    }
   ],
   "source": [
    "index_to_word = {}\n",
    "for key, value in tokenizer.word_index.items(): # 인덱스를 단어로 바꾸기 위해 index_to_word를 생성\n",
    "    index_to_word[value] = key\n",
    "\n",
    "print('빈도수 상위 582번 단어 : {}'.format(index_to_word[582]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36e6422",
   "metadata": {},
   "source": [
    "#### 데이터를 분리하기 전에 전체 샘플의 길이를 동일하게 만드는 패딩 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "098ab80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 24\n"
     ]
    }
   ],
   "source": [
    "# 패딩 작업을 수행하기 전에 가장 긴 샘플의 길이를 확인\n",
    "\n",
    "max_len = max(len(l) for l in sequences)\n",
    "print('샘플의 최대 길이 : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9c08e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   99  269]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0   99  269  371]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0   99  269  371 1115]]\n"
     ]
    }
   ],
   "source": [
    "# 가장 긴 샘플의 길이인 24로 모든 샘플의 길이를 패딩\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "print(sequences[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e7bf7594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맨 우측 단어만 레이블로 분리\n",
    "sequences = np.array(sequences)\n",
    "x = sequences[:,:-1]\n",
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "552b5b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,  99],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,  99, 269],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,  99, 269, 371]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78bc930b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 269,  371, 1115])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48a01654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 데이터 y에 대한 원-핫인코딩 수행\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dd4575",
   "metadata": {},
   "source": [
    "#### 모델 설계\n",
    "\n",
    "임베딩 벡터의 차원은 10, 은닉 상태의 크기는 128\n",
    "\n",
    "다 대 일 구조의 LSTM 사용 (다중 클래스 분류 문제)\n",
    "- 출력층에 소프트맥스 함수\n",
    "- 손실함수 크로스 엔트로피 함수\n",
    "\n",
    "전결합층(Fully Connected Layer)을 출력층으로 단어 집합 크기만큼의 뉴런을 배치\n",
    "\n",
    "200 에포크 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2757c9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "244/244 - 5s - loss: 7.6518 - accuracy: 0.0278 - 5s/epoch - 21ms/step\n",
      "Epoch 2/200\n",
      "244/244 - 3s - loss: 7.1183 - accuracy: 0.0291 - 3s/epoch - 14ms/step\n",
      "Epoch 3/200\n",
      "244/244 - 3s - loss: 6.9824 - accuracy: 0.0340 - 3s/epoch - 14ms/step\n",
      "Epoch 4/200\n",
      "244/244 - 4s - loss: 6.8589 - accuracy: 0.0395 - 4s/epoch - 14ms/step\n",
      "Epoch 5/200\n",
      "244/244 - 3s - loss: 6.7113 - accuracy: 0.0450 - 3s/epoch - 14ms/step\n",
      "Epoch 6/200\n",
      "244/244 - 3s - loss: 6.5402 - accuracy: 0.0493 - 3s/epoch - 14ms/step\n",
      "Epoch 7/200\n",
      "244/244 - 3s - loss: 6.3458 - accuracy: 0.0541 - 3s/epoch - 14ms/step\n",
      "Epoch 8/200\n",
      "244/244 - 4s - loss: 6.1461 - accuracy: 0.0593 - 4s/epoch - 14ms/step\n",
      "Epoch 9/200\n",
      "244/244 - 4s - loss: 5.9500 - accuracy: 0.0620 - 4s/epoch - 14ms/step\n",
      "Epoch 10/200\n",
      "244/244 - 3s - loss: 5.7659 - accuracy: 0.0654 - 3s/epoch - 14ms/step\n",
      "Epoch 11/200\n",
      "244/244 - 4s - loss: 5.5904 - accuracy: 0.0714 - 4s/epoch - 14ms/step\n",
      "Epoch 12/200\n",
      "244/244 - 3s - loss: 5.4268 - accuracy: 0.0757 - 3s/epoch - 14ms/step\n",
      "Epoch 13/200\n",
      "244/244 - 3s - loss: 5.2751 - accuracy: 0.0818 - 3s/epoch - 14ms/step\n",
      "Epoch 14/200\n",
      "244/244 - 3s - loss: 5.1250 - accuracy: 0.0921 - 3s/epoch - 14ms/step\n",
      "Epoch 15/200\n",
      "244/244 - 3s - loss: 4.9849 - accuracy: 0.0993 - 3s/epoch - 14ms/step\n",
      "Epoch 16/200\n",
      "244/244 - 3s - loss: 4.8495 - accuracy: 0.1070 - 3s/epoch - 14ms/step\n",
      "Epoch 17/200\n",
      "244/244 - 3s - loss: 4.7209 - accuracy: 0.1207 - 3s/epoch - 14ms/step\n",
      "Epoch 18/200\n",
      "244/244 - 3s - loss: 4.5960 - accuracy: 0.1317 - 3s/epoch - 14ms/step\n",
      "Epoch 19/200\n",
      "244/244 - 4s - loss: 4.4775 - accuracy: 0.1461 - 4s/epoch - 14ms/step\n",
      "Epoch 20/200\n",
      "244/244 - 3s - loss: 4.3599 - accuracy: 0.1613 - 3s/epoch - 14ms/step\n",
      "Epoch 21/200\n",
      "244/244 - 4s - loss: 4.2447 - accuracy: 0.1760 - 4s/epoch - 15ms/step\n",
      "Epoch 22/200\n",
      "244/244 - 3s - loss: 4.1319 - accuracy: 0.1913 - 3s/epoch - 14ms/step\n",
      "Epoch 23/200\n",
      "244/244 - 3s - loss: 4.0277 - accuracy: 0.2090 - 3s/epoch - 14ms/step\n",
      "Epoch 24/200\n",
      "244/244 - 4s - loss: 3.9198 - accuracy: 0.2275 - 4s/epoch - 15ms/step\n",
      "Epoch 25/200\n",
      "244/244 - 4s - loss: 3.8150 - accuracy: 0.2426 - 4s/epoch - 16ms/step\n",
      "Epoch 26/200\n",
      "244/244 - 4s - loss: 3.7147 - accuracy: 0.2668 - 4s/epoch - 15ms/step\n",
      "Epoch 27/200\n",
      "244/244 - 4s - loss: 3.6161 - accuracy: 0.2817 - 4s/epoch - 15ms/step\n",
      "Epoch 28/200\n",
      "244/244 - 3s - loss: 3.5213 - accuracy: 0.2946 - 3s/epoch - 14ms/step\n",
      "Epoch 29/200\n",
      "244/244 - 3s - loss: 3.4295 - accuracy: 0.3128 - 3s/epoch - 14ms/step\n",
      "Epoch 30/200\n",
      "244/244 - 4s - loss: 3.3398 - accuracy: 0.3287 - 4s/epoch - 15ms/step\n",
      "Epoch 31/200\n",
      "244/244 - 4s - loss: 3.2536 - accuracy: 0.3461 - 4s/epoch - 14ms/step\n",
      "Epoch 32/200\n",
      "244/244 - 4s - loss: 3.1661 - accuracy: 0.3652 - 4s/epoch - 15ms/step\n",
      "Epoch 33/200\n",
      "244/244 - 4s - loss: 3.0865 - accuracy: 0.3759 - 4s/epoch - 14ms/step\n",
      "Epoch 34/200\n",
      "244/244 - 3s - loss: 3.0044 - accuracy: 0.3911 - 3s/epoch - 14ms/step\n",
      "Epoch 35/200\n",
      "244/244 - 4s - loss: 2.9295 - accuracy: 0.4052 - 4s/epoch - 15ms/step\n",
      "Epoch 36/200\n",
      "244/244 - 4s - loss: 2.8538 - accuracy: 0.4175 - 4s/epoch - 15ms/step\n",
      "Epoch 37/200\n",
      "244/244 - 4s - loss: 2.7819 - accuracy: 0.4355 - 4s/epoch - 14ms/step\n",
      "Epoch 38/200\n",
      "244/244 - 3s - loss: 2.7113 - accuracy: 0.4455 - 3s/epoch - 14ms/step\n",
      "Epoch 39/200\n",
      "244/244 - 3s - loss: 2.6456 - accuracy: 0.4617 - 3s/epoch - 14ms/step\n",
      "Epoch 40/200\n",
      "244/244 - 3s - loss: 2.5777 - accuracy: 0.4758 - 3s/epoch - 14ms/step\n",
      "Epoch 41/200\n",
      "244/244 - 4s - loss: 2.5166 - accuracy: 0.4874 - 4s/epoch - 16ms/step\n",
      "Epoch 42/200\n",
      "244/244 - 4s - loss: 2.4510 - accuracy: 0.5026 - 4s/epoch - 15ms/step\n",
      "Epoch 43/200\n",
      "244/244 - 4s - loss: 2.3917 - accuracy: 0.5103 - 4s/epoch - 15ms/step\n",
      "Epoch 44/200\n",
      "244/244 - 4s - loss: 2.3347 - accuracy: 0.5238 - 4s/epoch - 15ms/step\n",
      "Epoch 45/200\n",
      "244/244 - 3s - loss: 2.2796 - accuracy: 0.5358 - 3s/epoch - 14ms/step\n",
      "Epoch 46/200\n",
      "244/244 - 3s - loss: 2.2220 - accuracy: 0.5448 - 3s/epoch - 14ms/step\n",
      "Epoch 47/200\n",
      "244/244 - 3s - loss: 2.1709 - accuracy: 0.5568 - 3s/epoch - 14ms/step\n",
      "Epoch 48/200\n",
      "244/244 - 3s - loss: 2.1196 - accuracy: 0.5647 - 3s/epoch - 14ms/step\n",
      "Epoch 49/200\n",
      "244/244 - 3s - loss: 2.0707 - accuracy: 0.5798 - 3s/epoch - 14ms/step\n",
      "Epoch 50/200\n",
      "244/244 - 4s - loss: 2.0193 - accuracy: 0.5893 - 4s/epoch - 14ms/step\n",
      "Epoch 51/200\n",
      "244/244 - 4s - loss: 1.9716 - accuracy: 0.5990 - 4s/epoch - 14ms/step\n",
      "Epoch 52/200\n",
      "244/244 - 4s - loss: 1.9268 - accuracy: 0.6081 - 4s/epoch - 15ms/step\n",
      "Epoch 53/200\n",
      "244/244 - 4s - loss: 1.8807 - accuracy: 0.6169 - 4s/epoch - 15ms/step\n",
      "Epoch 54/200\n",
      "244/244 - 4s - loss: 1.8373 - accuracy: 0.6237 - 4s/epoch - 14ms/step\n",
      "Epoch 55/200\n",
      "244/244 - 3s - loss: 1.7953 - accuracy: 0.6390 - 3s/epoch - 14ms/step\n",
      "Epoch 56/200\n",
      "244/244 - 3s - loss: 1.7521 - accuracy: 0.6437 - 3s/epoch - 14ms/step\n",
      "Epoch 57/200\n",
      "244/244 - 3s - loss: 1.7112 - accuracy: 0.6535 - 3s/epoch - 14ms/step\n",
      "Epoch 58/200\n",
      "244/244 - 3s - loss: 1.6728 - accuracy: 0.6635 - 3s/epoch - 14ms/step\n",
      "Epoch 59/200\n",
      "244/244 - 3s - loss: 1.6318 - accuracy: 0.6720 - 3s/epoch - 14ms/step\n",
      "Epoch 60/200\n",
      "244/244 - 3s - loss: 1.5941 - accuracy: 0.6797 - 3s/epoch - 14ms/step\n",
      "Epoch 61/200\n",
      "244/244 - 4s - loss: 1.5583 - accuracy: 0.6860 - 4s/epoch - 15ms/step\n",
      "Epoch 62/200\n",
      "244/244 - 3s - loss: 1.5218 - accuracy: 0.6950 - 3s/epoch - 14ms/step\n",
      "Epoch 63/200\n",
      "244/244 - 3s - loss: 1.4875 - accuracy: 0.7045 - 3s/epoch - 14ms/step\n",
      "Epoch 64/200\n",
      "244/244 - 3s - loss: 1.4560 - accuracy: 0.7087 - 3s/epoch - 14ms/step\n",
      "Epoch 65/200\n",
      "244/244 - 3s - loss: 1.4192 - accuracy: 0.7166 - 3s/epoch - 14ms/step\n",
      "Epoch 66/200\n",
      "244/244 - 3s - loss: 1.3872 - accuracy: 0.7227 - 3s/epoch - 14ms/step\n",
      "Epoch 67/200\n",
      "244/244 - 3s - loss: 1.3528 - accuracy: 0.7329 - 3s/epoch - 14ms/step\n",
      "Epoch 68/200\n",
      "244/244 - 3s - loss: 1.3212 - accuracy: 0.7400 - 3s/epoch - 14ms/step\n",
      "Epoch 69/200\n",
      "244/244 - 4s - loss: 1.2917 - accuracy: 0.7488 - 4s/epoch - 14ms/step\n",
      "Epoch 70/200\n",
      "244/244 - 4s - loss: 1.2625 - accuracy: 0.7523 - 4s/epoch - 15ms/step\n",
      "Epoch 71/200\n",
      "244/244 - 3s - loss: 1.2341 - accuracy: 0.7551 - 3s/epoch - 14ms/step\n",
      "Epoch 72/200\n",
      "244/244 - 3s - loss: 1.2036 - accuracy: 0.7642 - 3s/epoch - 14ms/step\n",
      "Epoch 73/200\n",
      "244/244 - 3s - loss: 1.1774 - accuracy: 0.7665 - 3s/epoch - 14ms/step\n",
      "Epoch 74/200\n",
      "244/244 - 3s - loss: 1.1477 - accuracy: 0.7744 - 3s/epoch - 14ms/step\n",
      "Epoch 75/200\n",
      "244/244 - 3s - loss: 1.1235 - accuracy: 0.7769 - 3s/epoch - 14ms/step\n",
      "Epoch 76/200\n",
      "244/244 - 3s - loss: 1.0956 - accuracy: 0.7833 - 3s/epoch - 14ms/step\n",
      "Epoch 77/200\n",
      "244/244 - 3s - loss: 1.0695 - accuracy: 0.7929 - 3s/epoch - 14ms/step\n",
      "Epoch 78/200\n",
      "244/244 - 3s - loss: 1.0444 - accuracy: 0.7948 - 3s/epoch - 14ms/step\n",
      "Epoch 79/200\n",
      "244/244 - 3s - loss: 1.0211 - accuracy: 0.8008 - 3s/epoch - 14ms/step\n",
      "Epoch 80/200\n",
      "244/244 - 4s - loss: 0.9990 - accuracy: 0.8055 - 4s/epoch - 15ms/step\n",
      "Epoch 81/200\n",
      "244/244 - 4s - loss: 0.9736 - accuracy: 0.8094 - 4s/epoch - 15ms/step\n",
      "Epoch 82/200\n",
      "244/244 - 4s - loss: 0.9524 - accuracy: 0.8146 - 4s/epoch - 14ms/step\n",
      "Epoch 83/200\n",
      "244/244 - 3s - loss: 0.9324 - accuracy: 0.8185 - 3s/epoch - 14ms/step\n",
      "Epoch 84/200\n",
      "244/244 - 3s - loss: 0.9066 - accuracy: 0.8244 - 3s/epoch - 14ms/step\n",
      "Epoch 85/200\n",
      "244/244 - 3s - loss: 0.8861 - accuracy: 0.8269 - 3s/epoch - 14ms/step\n",
      "Epoch 86/200\n",
      "244/244 - 3s - loss: 0.8667 - accuracy: 0.8311 - 3s/epoch - 14ms/step\n",
      "Epoch 87/200\n",
      "244/244 - 3s - loss: 0.8483 - accuracy: 0.8362 - 3s/epoch - 14ms/step\n",
      "Epoch 88/200\n",
      "244/244 - 3s - loss: 0.8292 - accuracy: 0.8374 - 3s/epoch - 14ms/step\n",
      "Epoch 89/200\n",
      "244/244 - 3s - loss: 0.8092 - accuracy: 0.8415 - 3s/epoch - 14ms/step\n",
      "Epoch 90/200\n",
      "244/244 - 3s - loss: 0.7913 - accuracy: 0.8442 - 3s/epoch - 14ms/step\n",
      "Epoch 91/200\n",
      "244/244 - 3s - loss: 0.7779 - accuracy: 0.8485 - 3s/epoch - 14ms/step\n",
      "Epoch 92/200\n",
      "244/244 - 3s - loss: 0.7572 - accuracy: 0.8525 - 3s/epoch - 14ms/step\n",
      "Epoch 93/200\n",
      "244/244 - 3s - loss: 0.7410 - accuracy: 0.8545 - 3s/epoch - 14ms/step\n",
      "Epoch 94/200\n",
      "244/244 - 3s - loss: 0.7234 - accuracy: 0.8581 - 3s/epoch - 14ms/step\n",
      "Epoch 95/200\n",
      "244/244 - 3s - loss: 0.7074 - accuracy: 0.8612 - 3s/epoch - 14ms/step\n",
      "Epoch 96/200\n",
      "244/244 - 3s - loss: 0.6920 - accuracy: 0.8643 - 3s/epoch - 14ms/step\n",
      "Epoch 97/200\n",
      "244/244 - 3s - loss: 0.6754 - accuracy: 0.8657 - 3s/epoch - 14ms/step\n",
      "Epoch 98/200\n",
      "244/244 - 3s - loss: 0.6637 - accuracy: 0.8688 - 3s/epoch - 14ms/step\n",
      "Epoch 99/200\n",
      "244/244 - 3s - loss: 0.6507 - accuracy: 0.8693 - 3s/epoch - 14ms/step\n",
      "Epoch 100/200\n",
      "244/244 - 3s - loss: 0.6361 - accuracy: 0.8758 - 3s/epoch - 14ms/step\n",
      "Epoch 101/200\n",
      "244/244 - 3s - loss: 0.6221 - accuracy: 0.8761 - 3s/epoch - 14ms/step\n",
      "Epoch 102/200\n",
      "244/244 - 3s - loss: 0.6106 - accuracy: 0.8794 - 3s/epoch - 14ms/step\n",
      "Epoch 103/200\n",
      "244/244 - 3s - loss: 0.5985 - accuracy: 0.8815 - 3s/epoch - 14ms/step\n",
      "Epoch 104/200\n",
      "244/244 - 4s - loss: 0.5854 - accuracy: 0.8826 - 4s/epoch - 14ms/step\n",
      "Epoch 105/200\n",
      "244/244 - 3s - loss: 0.5774 - accuracy: 0.8834 - 3s/epoch - 14ms/step\n",
      "Epoch 106/200\n",
      "244/244 - 3s - loss: 0.5624 - accuracy: 0.8877 - 3s/epoch - 14ms/step\n",
      "Epoch 107/200\n",
      "244/244 - 3s - loss: 0.5519 - accuracy: 0.8868 - 3s/epoch - 14ms/step\n",
      "Epoch 108/200\n",
      "244/244 - 3s - loss: 0.5401 - accuracy: 0.8920 - 3s/epoch - 14ms/step\n",
      "Epoch 109/200\n",
      "244/244 - 3s - loss: 0.5300 - accuracy: 0.8912 - 3s/epoch - 14ms/step\n",
      "Epoch 110/200\n",
      "244/244 - 3s - loss: 0.5199 - accuracy: 0.8944 - 3s/epoch - 14ms/step\n",
      "Epoch 111/200\n",
      "244/244 - 3s - loss: 0.5119 - accuracy: 0.8947 - 3s/epoch - 14ms/step\n",
      "Epoch 112/200\n",
      "244/244 - 3s - loss: 0.5005 - accuracy: 0.8972 - 3s/epoch - 14ms/step\n",
      "Epoch 113/200\n",
      "244/244 - 3s - loss: 0.4911 - accuracy: 0.8976 - 3s/epoch - 14ms/step\n",
      "Epoch 114/200\n",
      "244/244 - 3s - loss: 0.4821 - accuracy: 0.9002 - 3s/epoch - 14ms/step\n",
      "Epoch 115/200\n",
      "244/244 - 3s - loss: 0.4741 - accuracy: 0.9008 - 3s/epoch - 14ms/step\n",
      "Epoch 116/200\n",
      "244/244 - 3s - loss: 0.4688 - accuracy: 0.9012 - 3s/epoch - 14ms/step\n",
      "Epoch 117/200\n",
      "244/244 - 3s - loss: 0.4601 - accuracy: 0.9006 - 3s/epoch - 14ms/step\n",
      "Epoch 118/200\n",
      "244/244 - 3s - loss: 0.4530 - accuracy: 0.9029 - 3s/epoch - 14ms/step\n",
      "Epoch 119/200\n",
      "244/244 - 3s - loss: 0.4464 - accuracy: 0.9039 - 3s/epoch - 14ms/step\n",
      "Epoch 120/200\n",
      "244/244 - 3s - loss: 0.4368 - accuracy: 0.9044 - 3s/epoch - 14ms/step\n",
      "Epoch 121/200\n",
      "244/244 - 4s - loss: 0.4265 - accuracy: 0.9066 - 4s/epoch - 15ms/step\n",
      "Epoch 122/200\n",
      "244/244 - 4s - loss: 0.4196 - accuracy: 0.9052 - 4s/epoch - 16ms/step\n",
      "Epoch 123/200\n",
      "244/244 - 4s - loss: 0.4169 - accuracy: 0.9086 - 4s/epoch - 15ms/step\n",
      "Epoch 124/200\n",
      "244/244 - 4s - loss: 0.4071 - accuracy: 0.9091 - 4s/epoch - 15ms/step\n",
      "Epoch 125/200\n",
      "244/244 - 4s - loss: 0.4000 - accuracy: 0.9086 - 4s/epoch - 15ms/step\n",
      "Epoch 126/200\n",
      "244/244 - 4s - loss: 0.3955 - accuracy: 0.9099 - 4s/epoch - 15ms/step\n",
      "Epoch 127/200\n",
      "244/244 - 3s - loss: 0.3895 - accuracy: 0.9104 - 3s/epoch - 14ms/step\n",
      "Epoch 128/200\n",
      "244/244 - 4s - loss: 0.3857 - accuracy: 0.9104 - 4s/epoch - 15ms/step\n",
      "Epoch 129/200\n",
      "244/244 - 3s - loss: 0.3880 - accuracy: 0.9103 - 3s/epoch - 14ms/step\n",
      "Epoch 130/200\n",
      "244/244 - 3s - loss: 0.3790 - accuracy: 0.9132 - 3s/epoch - 14ms/step\n",
      "Epoch 131/200\n",
      "244/244 - 4s - loss: 0.3705 - accuracy: 0.9117 - 4s/epoch - 14ms/step\n",
      "Epoch 132/200\n",
      "244/244 - 3s - loss: 0.3624 - accuracy: 0.9129 - 3s/epoch - 14ms/step\n",
      "Epoch 133/200\n",
      "244/244 - 3s - loss: 0.3594 - accuracy: 0.9123 - 3s/epoch - 14ms/step\n",
      "Epoch 134/200\n",
      "244/244 - 3s - loss: 0.3556 - accuracy: 0.9146 - 3s/epoch - 14ms/step\n",
      "Epoch 135/200\n",
      "244/244 - 3s - loss: 0.3534 - accuracy: 0.9138 - 3s/epoch - 14ms/step\n",
      "Epoch 136/200\n",
      "244/244 - 3s - loss: 0.3460 - accuracy: 0.9144 - 3s/epoch - 14ms/step\n",
      "Epoch 137/200\n",
      "244/244 - 3s - loss: 0.3461 - accuracy: 0.9146 - 3s/epoch - 14ms/step\n",
      "Epoch 138/200\n",
      "244/244 - 3s - loss: 0.3412 - accuracy: 0.9153 - 3s/epoch - 14ms/step\n",
      "Epoch 139/200\n",
      "244/244 - 3s - loss: 0.3373 - accuracy: 0.9152 - 3s/epoch - 14ms/step\n",
      "Epoch 140/200\n",
      "244/244 - 3s - loss: 0.3333 - accuracy: 0.9148 - 3s/epoch - 14ms/step\n",
      "Epoch 141/200\n",
      "244/244 - 3s - loss: 0.3322 - accuracy: 0.9150 - 3s/epoch - 14ms/step\n",
      "Epoch 142/200\n",
      "244/244 - 3s - loss: 0.3320 - accuracy: 0.9153 - 3s/epoch - 14ms/step\n",
      "Epoch 143/200\n",
      "244/244 - 3s - loss: 0.3260 - accuracy: 0.9152 - 3s/epoch - 14ms/step\n",
      "Epoch 144/200\n",
      "244/244 - 3s - loss: 0.3207 - accuracy: 0.9164 - 3s/epoch - 14ms/step\n",
      "Epoch 145/200\n",
      "244/244 - 3s - loss: 0.3178 - accuracy: 0.9153 - 3s/epoch - 14ms/step\n",
      "Epoch 146/200\n",
      "244/244 - 3s - loss: 0.3150 - accuracy: 0.9154 - 3s/epoch - 14ms/step\n",
      "Epoch 147/200\n",
      "244/244 - 3s - loss: 0.3324 - accuracy: 0.9127 - 3s/epoch - 14ms/step\n",
      "Epoch 148/200\n",
      "244/244 - 3s - loss: 0.3609 - accuracy: 0.9055 - 3s/epoch - 14ms/step\n",
      "Epoch 149/200\n",
      "244/244 - 3s - loss: 0.3153 - accuracy: 0.9150 - 3s/epoch - 14ms/step\n",
      "Epoch 150/200\n",
      "244/244 - 4s - loss: 0.3064 - accuracy: 0.9154 - 4s/epoch - 14ms/step\n",
      "Epoch 151/200\n",
      "244/244 - 3s - loss: 0.3033 - accuracy: 0.9159 - 3s/epoch - 14ms/step\n",
      "Epoch 152/200\n",
      "244/244 - 3s - loss: 0.3001 - accuracy: 0.9148 - 3s/epoch - 14ms/step\n",
      "Epoch 153/200\n",
      "244/244 - 3s - loss: 0.3013 - accuracy: 0.9162 - 3s/epoch - 14ms/step\n",
      "Epoch 154/200\n",
      "244/244 - 3s - loss: 0.2980 - accuracy: 0.9154 - 3s/epoch - 14ms/step\n",
      "Epoch 155/200\n",
      "244/244 - 3s - loss: 0.2972 - accuracy: 0.9162 - 3s/epoch - 14ms/step\n",
      "Epoch 156/200\n",
      "244/244 - 3s - loss: 0.2954 - accuracy: 0.9154 - 3s/epoch - 14ms/step\n",
      "Epoch 157/200\n",
      "244/244 - 3s - loss: 0.2964 - accuracy: 0.9148 - 3s/epoch - 14ms/step\n",
      "Epoch 158/200\n",
      "244/244 - 3s - loss: 0.2949 - accuracy: 0.9159 - 3s/epoch - 14ms/step\n",
      "Epoch 159/200\n",
      "244/244 - 3s - loss: 0.2919 - accuracy: 0.9153 - 3s/epoch - 14ms/step\n",
      "Epoch 160/200\n",
      "244/244 - 3s - loss: 0.2901 - accuracy: 0.9161 - 3s/epoch - 14ms/step\n",
      "Epoch 161/200\n",
      "244/244 - 3s - loss: 0.2890 - accuracy: 0.9162 - 3s/epoch - 14ms/step\n",
      "Epoch 162/200\n",
      "244/244 - 3s - loss: 0.2890 - accuracy: 0.9148 - 3s/epoch - 14ms/step\n",
      "Epoch 163/200\n",
      "244/244 - 3s - loss: 0.2867 - accuracy: 0.9161 - 3s/epoch - 14ms/step\n",
      "Epoch 164/200\n",
      "244/244 - 4s - loss: 0.2864 - accuracy: 0.9172 - 4s/epoch - 15ms/step\n",
      "Epoch 165/200\n",
      "244/244 - 4s - loss: 0.2848 - accuracy: 0.9159 - 4s/epoch - 15ms/step\n",
      "Epoch 166/200\n",
      "244/244 - 3s - loss: 0.2826 - accuracy: 0.9162 - 3s/epoch - 14ms/step\n",
      "Epoch 167/200\n",
      "244/244 - 3s - loss: 0.2827 - accuracy: 0.9155 - 3s/epoch - 14ms/step\n",
      "Epoch 168/200\n",
      "244/244 - 3s - loss: 0.2810 - accuracy: 0.9163 - 3s/epoch - 14ms/step\n",
      "Epoch 169/200\n",
      "244/244 - 3s - loss: 0.3162 - accuracy: 0.9097 - 3s/epoch - 14ms/step\n",
      "Epoch 170/200\n",
      "244/244 - 3s - loss: 0.3126 - accuracy: 0.9109 - 3s/epoch - 14ms/step\n",
      "Epoch 171/200\n",
      "244/244 - 3s - loss: 0.2941 - accuracy: 0.9132 - 3s/epoch - 14ms/step\n",
      "Epoch 172/200\n",
      "244/244 - 3s - loss: 0.2807 - accuracy: 0.9148 - 3s/epoch - 14ms/step\n",
      "Epoch 173/200\n",
      "244/244 - 3s - loss: 0.2765 - accuracy: 0.9172 - 3s/epoch - 14ms/step\n",
      "Epoch 174/200\n",
      "244/244 - 3s - loss: 0.2742 - accuracy: 0.9170 - 3s/epoch - 14ms/step\n",
      "Epoch 175/200\n",
      "244/244 - 3s - loss: 0.2752 - accuracy: 0.9163 - 3s/epoch - 14ms/step\n",
      "Epoch 176/200\n",
      "244/244 - 3s - loss: 0.2738 - accuracy: 0.9179 - 3s/epoch - 14ms/step\n",
      "Epoch 177/200\n",
      "244/244 - 3s - loss: 0.2739 - accuracy: 0.9154 - 3s/epoch - 14ms/step\n",
      "Epoch 178/200\n",
      "244/244 - 4s - loss: 0.2733 - accuracy: 0.9159 - 4s/epoch - 15ms/step\n",
      "Epoch 179/200\n",
      "244/244 - 4s - loss: 0.2730 - accuracy: 0.9153 - 4s/epoch - 14ms/step\n",
      "Epoch 180/200\n",
      "244/244 - 3s - loss: 0.2724 - accuracy: 0.9153 - 3s/epoch - 14ms/step\n",
      "Epoch 181/200\n",
      "244/244 - 3s - loss: 0.2734 - accuracy: 0.9173 - 3s/epoch - 14ms/step\n",
      "Epoch 182/200\n",
      "244/244 - 4s - loss: 0.2720 - accuracy: 0.9159 - 4s/epoch - 14ms/step\n",
      "Epoch 183/200\n",
      "244/244 - 3s - loss: 0.2802 - accuracy: 0.9138 - 3s/epoch - 14ms/step\n",
      "Epoch 184/200\n",
      "244/244 - 3s - loss: 0.2738 - accuracy: 0.9163 - 3s/epoch - 14ms/step\n",
      "Epoch 185/200\n",
      "244/244 - 3s - loss: 0.2705 - accuracy: 0.9164 - 3s/epoch - 14ms/step\n",
      "Epoch 186/200\n",
      "244/244 - 3s - loss: 0.2690 - accuracy: 0.9153 - 3s/epoch - 14ms/step\n",
      "Epoch 187/200\n",
      "244/244 - 3s - loss: 0.2691 - accuracy: 0.9163 - 3s/epoch - 14ms/step\n",
      "Epoch 188/200\n",
      "244/244 - 3s - loss: 0.2681 - accuracy: 0.9166 - 3s/epoch - 14ms/step\n",
      "Epoch 189/200\n",
      "244/244 - 3s - loss: 0.2696 - accuracy: 0.9150 - 3s/epoch - 14ms/step\n",
      "Epoch 190/200\n",
      "244/244 - 3s - loss: 0.2682 - accuracy: 0.9146 - 3s/epoch - 14ms/step\n",
      "Epoch 191/200\n",
      "244/244 - 3s - loss: 0.2672 - accuracy: 0.9154 - 3s/epoch - 14ms/step\n",
      "Epoch 192/200\n",
      "244/244 - 3s - loss: 0.2669 - accuracy: 0.9153 - 3s/epoch - 14ms/step\n",
      "Epoch 193/200\n",
      "244/244 - 3s - loss: 0.2655 - accuracy: 0.9161 - 3s/epoch - 14ms/step\n",
      "Epoch 194/200\n",
      "244/244 - 4s - loss: 0.2656 - accuracy: 0.9157 - 4s/epoch - 14ms/step\n",
      "Epoch 195/200\n",
      "244/244 - 3s - loss: 0.2654 - accuracy: 0.9163 - 3s/epoch - 14ms/step\n",
      "Epoch 196/200\n",
      "244/244 - 3s - loss: 0.2643 - accuracy: 0.9166 - 3s/epoch - 14ms/step\n",
      "Epoch 197/200\n",
      "244/244 - 3s - loss: 0.2648 - accuracy: 0.9164 - 3s/epoch - 14ms/step\n",
      "Epoch 198/200\n",
      "244/244 - 3s - loss: 0.2630 - accuracy: 0.9159 - 3s/epoch - 14ms/step\n",
      "Epoch 199/200\n",
      "244/244 - 3s - loss: 0.2645 - accuracy: 0.9150 - 3s/epoch - 14ms/step\n",
      "Epoch 200/200\n",
      "244/244 - 4s - loss: 0.2642 - accuracy: 0.9170 - 4s/epoch - 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21841bd93a0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "\n",
    "embedding_dim = 10\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b99e2f",
   "metadata": {},
   "source": [
    "#### 문장을 생성하는 함수 sentence_generation로 (상단에 정의) 문장을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "441037ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i judgment first be student window office golden muellers recap very\n"
     ]
    }
   ],
   "source": [
    "# 임의의 단어 'i'에 대해서 10개의 단어를 추가 생성\n",
    "print(sentence_generation(model, tokenizer, 'i', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a377ef9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to judgment is us new match hero hero outside office\n"
     ]
    }
   ],
   "source": [
    "# 임의의 단어 'how'에 대해서 10개의 단어를 추가 생성\n",
    "print(sentence_generation(model, tokenizer, 'how', 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6470e9",
   "metadata": {},
   "source": [
    "## 8-7 문자단위 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a86cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
